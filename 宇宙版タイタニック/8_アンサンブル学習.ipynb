{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング\n",
    "1. 使わない特徴量を削除\n",
    "2. カテゴリカルデータをラベルエンコーディング \n",
    "3. 欠損値を埋める。(LightGBM)\n",
    "4. データの特性から特徴量を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_split = df['Cabin'].str.split('/', expand=True)\n",
    "# Deck 列を作成\n",
    "df['Deck'] = cabin_split[0]    \n",
    "# Side 列を作成し、条件に基づいて数値を割り当て\n",
    "df['Side'] = cabin_split[2].map({'P': True, 'S': False})\n",
    "df['Side'] = df['Side'].astype(bool)\n",
    "\n",
    "# PassengerId から GroupID と Person Number を抽出\n",
    "df['GroupID'] = df['PassengerId'].apply(lambda x: x.split('_')[0])\n",
    "# Group Size を計算\n",
    "group_sizes = df.groupby('GroupID').size()\n",
    "df['GroupSize'] = df['GroupID'].apply(lambda x: group_sizes[x])\n",
    "# Is Alone 特徴量を追加\n",
    "df['IsAlone'] = (df['GroupSize'] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['PassengerId', 'Cabin', 'Name','GroupID']\n",
    "cat_cols = ['HomePlanet', 'CryoSleep', 'Destination','VIP','Deck','Side', 'IsAlone' ,'GroupSize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # カラム数に基づいて行と列の数を設定\n",
    "\n",
    "# cols = 3  # 3列で表示\n",
    "# rows = (len(cat_cols) + cols - 1) // cols  # 必要な行数を計算\n",
    "\n",
    "# # サブプロットの設定\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(12, 5 * rows))  # 各サブプロットのサイズを調整\n",
    "# axes = axes.flatten()  # 1Dに変換してインデックスでアクセスしやすくする\n",
    "\n",
    "# # 各カラムについてプロット\n",
    "# for i, name in enumerate(cat_cols):\n",
    "#     sns.countplot(x=name, hue='Transported', data=df, ax=axes[i])\n",
    "#     axes[i].set_title(f'{name} vs. Transported')\n",
    "#     axes[i].tick_params(axis='x', rotation=45)  # x軸のラベルを回転して表示\n",
    "\n",
    "# # 余分なサブプロットを非表示\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoomService の欠損値を条件に基づいて埋める\n",
    "df_drop['RoomService'] = df_drop.apply(\n",
    "    lambda row: 0 if pd.isna(row['RoomService']) and row['CryoSleep'] else row['RoomService'],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_drop[c])\n",
    "    df_drop[c] = le.transform(df_drop[c])\n",
    "\n",
    "for c in cat_cols:\n",
    "    df_drop[c] = df_drop[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Age\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1317\n",
      "[LightGBM] [Info] Number of data points in the train set: 6811, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 28.770518\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttrain's l2: 150.751\tvalid's l2: 166.763\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RoomService\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1172\n",
      "[LightGBM] [Info] Number of data points in the train set: 6865, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 228.005098\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttrain's l2: 225302\tvalid's l2: 251329\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FoodCourt\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1173\n",
      "[LightGBM] [Info] Number of data points in the train set: 6808, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 449.152027\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttrain's l2: 893108\tvalid's l2: 2.0948e+06\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ShoppingMall\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1172\n",
      "[LightGBM] [Info] Number of data points in the train set: 6788, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 172.471126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttrain's l2: 217534\tvalid's l2: 286604\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Spa\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1172\n",
      "[LightGBM] [Info] Number of data points in the train set: 6808, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 313.425382\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttrain's l2: 787522\tvalid's l2: 716235\n",
      "----------------------------------------------------------------------------------------------------\n",
      "VRDeck\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 6804, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 297.809965\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's l2: 589766\tvalid's l2: 1.0959e+06\n"
     ]
    }
   ],
   "source": [
    "columns_with_nulls = [col for col in df_drop.columns if df_drop[col].isna().any()]\n",
    "data = df_drop.drop(['Transported'], axis=1)\n",
    "for c in columns_with_nulls:\n",
    "    print('-'*100)\n",
    "    print(c)\n",
    "\n",
    "# 欠損値がある行とない行を分ける\n",
    "    train_data = data[data[c].notna()]\n",
    "    test_data = data[data[c].isna()]\n",
    "\n",
    "# 訓練データと検証データ\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train_data.drop(c, axis=1), \n",
    "        train_data[c],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    objective = 'multiclass' if c in ['HomePlanet', 'CryoSleep', 'Destination','VIP','Deck','Side', 'IsAlone' ,'GroupSize'] else 'regression'\n",
    "\n",
    "# LightGBMのパラメータ\n",
    "    params = {\n",
    "        'objective': objective,  # 目的変数が連続値の場合は'regression', カテゴリの場合は'multiclass'\n",
    "        'learning_rate': 0.1,\n",
    "        'lambda_l1' : 0.1,\n",
    "        'num_leaves': 20,\n",
    "        'random_state': 4\n",
    "    }\n",
    "\n",
    "# 訓練データセットを作成\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n",
    "\n",
    "# モデルの訓練\n",
    "    model = lgb.train(params,\n",
    "                      dtrain,\n",
    "                      num_boost_round=10000,\n",
    "                      valid_sets=[dtrain, dval],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      callbacks=[lgb.early_stopping(100),\n",
    "                      lgb.log_evaluation(500)])\n",
    "\n",
    "# テストデータで欠損値を予測\n",
    "    predicted_values = model.predict(test_data.drop(c, axis=1))\n",
    "\n",
    "# 欠損値の予済結果を元のデータセットに埋める\n",
    "    data.loc[data[c].isna(), c] = predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_usage'] = data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa']].sum(axis=1)\n",
    "data['is_youth'] = np.where(data['Age'] >= 40, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = df_drop.drop(['Transported'], axis=1)\n",
    "X = data\n",
    "y = df_drop['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n最初にデータを訓練データとテストデータに分割\\n次に訓練データをさらに訓練データと検証データに分割\\nX_train, y_train : 訓練データ\\nX_val, y_val : 検証データ\\nX_test, y_test : テストデータ\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=0 )\n",
    "\"\"\"\n",
    "最初にデータを訓練データとテストデータに分割\n",
    "次に訓練データをさらに訓練データと検証データに分割\n",
    "X_train, y_train : 訓練データ\n",
    "X_val, y_val : 検証データ\n",
    "X_test, y_test : テストデータ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの構築(クロスバリデーション)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 10,\n",
    "    'seed': 0,\n",
    "    'verbose': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[343]\ttrain's binary_logloss: 0.278369\tvalid's binary_logloss: 0.377027\n",
      "fold 1 MAE valid: 0.24\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttrain's binary_logloss: 0.328394\tvalid's binary_logloss: 0.368127\n",
      "fold 2 MAE valid: 0.25\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttrain's binary_logloss: 0.30402\tvalid's binary_logloss: 0.412744\n",
      "fold 3 MAE valid: 0.26\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttrain's binary_logloss: 0.351977\tvalid's binary_logloss: 0.415968\n",
      "fold 4 MAE valid: 0.27\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttrain's binary_logloss: 0.327097\tvalid's binary_logloss: 0.371737\n",
      "fold 5 MAE valid: 0.25\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttrain's binary_logloss: 0.352544\tvalid's binary_logloss: 0.434403\n",
      "fold 6 MAE valid: 0.28\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttrain's binary_logloss: 0.355177\tvalid's binary_logloss: 0.423409\n",
      "fold 7 MAE valid: 0.27\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttrain's binary_logloss: 0.335634\tvalid's binary_logloss: 0.390922\n",
      "fold 8 MAE valid: 0.26\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttrain's binary_logloss: 0.337933\tvalid's binary_logloss: 0.376702\n",
      "fold 9 MAE valid: 0.25\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttrain's binary_logloss: 0.349983\tvalid's binary_logloss: 0.401761\n",
      "fold 10 MAE valid: 0.26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def crossVal(X_train, y_train, params):\n",
    "    # 格納用データの作成\n",
    "    valid_scores = []\n",
    "    models = []\n",
    "    oof = np.zeros(len(X_train))\n",
    "\n",
    "    # KFoldを用いて学習データを5分割してモデルを作成\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X_train)):\n",
    "        X_tr = X_train.iloc[tr_idx]\n",
    "        X_va = X_train.iloc[va_idx]\n",
    "        y_tr = y_train.iloc[tr_idx]\n",
    "        y_va = y_train.iloc[va_idx]\n",
    "    \n",
    "        lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "        lgb_eval = lgb.Dataset(X_va, y_va, reference=lgb_train)\n",
    "\n",
    "        # 最適化ハイパーパラメータを読み込み\n",
    "        model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      num_boost_round=10000,\n",
    "                      valid_sets=[lgb_train, lgb_eval],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      callbacks=[lgb.early_stopping(100),\n",
    "                      lgb.log_evaluation(500)])\n",
    "\n",
    "        y_va_pred = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "        score = mean_absolute_error(y_va, y_va_pred)\n",
    "        print(f'fold {fold+1} MAE valid: {score:.2f}')\n",
    "        print('')\n",
    "\n",
    "        # スコア、モデル、予測値の格納\n",
    "        valid_scores.append(score)\n",
    "        models.append(model)\n",
    "        oof[va_idx] = y_va_pred\n",
    "    return valid_scores, models,oof\n",
    "\n",
    "# クロスバリデーションの平均スコア\n",
    "valid_scores, models_lg,oof = crossVal(X_train, y_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6954 entries, 6617 to 3235\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   HomePlanet    6954 non-null   category\n",
      " 1   CryoSleep     6954 non-null   category\n",
      " 2   Destination   6954 non-null   category\n",
      " 3   Age           6954 non-null   float64 \n",
      " 4   VIP           6954 non-null   category\n",
      " 5   RoomService   6954 non-null   float64 \n",
      " 6   FoodCourt     6954 non-null   float64 \n",
      " 7   ShoppingMall  6954 non-null   float64 \n",
      " 8   Spa           6954 non-null   float64 \n",
      " 9   VRDeck        6954 non-null   float64 \n",
      " 10  Deck          6954 non-null   category\n",
      " 11  Side          6954 non-null   category\n",
      " 12  GroupSize     6954 non-null   category\n",
      " 13  IsAlone       6954 non-null   category\n",
      " 14  total_usage   6954 non-null   float64 \n",
      " 15  is_youth      6954 non-null   int64   \n",
      "dtypes: category(8), float64(7), int64(1)\n",
      "memory usage: 544.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.49719\tvalidation_1-rmse:0.49774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoto.ota/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-rmse:0.33559\tvalidation_1-rmse:0.39978\n",
      "[200]\tvalidation_0-rmse:0.27931\tvalidation_1-rmse:0.38693\n",
      "[268]\tvalidation_0-rmse:0.25887\tvalidation_1-rmse:0.38728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=5000, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=5000, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=5000, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=0, ...)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params ={'n_estimators':5000,\n",
    "             'max_depth': 10,\n",
    "             'learning_rate': 0.01,\n",
    "             'random_state':0,\n",
    "             }\n",
    "\n",
    "\n",
    "model = xgb.XGBRegressor(**xgb_params, enable_categorical=True)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "          early_stopping_rounds=50,\n",
    "          verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.49710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoto.ota/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-rmse:0.33198\n",
      "[200]\tvalidation_0-rmse:0.27342\n",
      "[300]\tvalidation_0-rmse:0.24190\n",
      "[400]\tvalidation_0-rmse:0.21843\n",
      "[500]\tvalidation_0-rmse:0.20579\n",
      "[600]\tvalidation_0-rmse:0.19948\n",
      "[700]\tvalidation_0-rmse:0.19422\n",
      "[800]\tvalidation_0-rmse:0.18580\n",
      "[900]\tvalidation_0-rmse:0.17826\n",
      "[1000]\tvalidation_0-rmse:0.17327\n",
      "[1100]\tvalidation_0-rmse:0.16916\n",
      "[1200]\tvalidation_0-rmse:0.16633\n",
      "[1300]\tvalidation_0-rmse:0.16310\n",
      "[1400]\tvalidation_0-rmse:0.16058\n",
      "[1500]\tvalidation_0-rmse:0.15752\n",
      "[1600]\tvalidation_0-rmse:0.15436\n",
      "[1700]\tvalidation_0-rmse:0.15186\n",
      "[1800]\tvalidation_0-rmse:0.15023\n",
      "[1900]\tvalidation_0-rmse:0.14887\n",
      "[2000]\tvalidation_0-rmse:0.14700\n",
      "[2100]\tvalidation_0-rmse:0.14592\n",
      "[2200]\tvalidation_0-rmse:0.14380\n",
      "[2300]\tvalidation_0-rmse:0.14149\n",
      "[2400]\tvalidation_0-rmse:0.13980\n",
      "[2500]\tvalidation_0-rmse:0.13800\n",
      "[2600]\tvalidation_0-rmse:0.13688\n",
      "[2700]\tvalidation_0-rmse:0.13391\n",
      "[2800]\tvalidation_0-rmse:0.13189\n",
      "[2900]\tvalidation_0-rmse:0.13040\n",
      "[3000]\tvalidation_0-rmse:0.12865\n",
      "[3100]\tvalidation_0-rmse:0.12806\n",
      "[3200]\tvalidation_0-rmse:0.12764\n",
      "[3300]\tvalidation_0-rmse:0.12668\n",
      "[3400]\tvalidation_0-rmse:0.12564\n",
      "[3500]\tvalidation_0-rmse:0.12466\n",
      "[3600]\tvalidation_0-rmse:0.12363\n",
      "[3700]\tvalidation_0-rmse:0.12289\n",
      "[3800]\tvalidation_0-rmse:0.12228\n",
      "[3900]\tvalidation_0-rmse:0.12210\n",
      "[4000]\tvalidation_0-rmse:0.12183\n",
      "[4100]\tvalidation_0-rmse:0.12123\n",
      "[4200]\tvalidation_0-rmse:0.12054\n",
      "[4300]\tvalidation_0-rmse:0.12001\n",
      "[4400]\tvalidation_0-rmse:0.11920\n",
      "[4500]\tvalidation_0-rmse:0.11846\n",
      "[4600]\tvalidation_0-rmse:0.11797\n",
      "[4700]\tvalidation_0-rmse:0.11756\n",
      "[4800]\tvalidation_0-rmse:0.11691\n",
      "[4900]\tvalidation_0-rmse:0.11639\n",
      "[4999]\tvalidation_0-rmse:0.11614\n",
      "fold 1 MAE valid: 0.26\n",
      "[0]\tvalidation_0-rmse:0.49702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoto.ota/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-rmse:0.32765\n",
      "[200]\tvalidation_0-rmse:0.26813\n",
      "[300]\tvalidation_0-rmse:0.23671\n",
      "[400]\tvalidation_0-rmse:0.21397\n",
      "[500]\tvalidation_0-rmse:0.20229\n",
      "[600]\tvalidation_0-rmse:0.19382\n",
      "[700]\tvalidation_0-rmse:0.18536\n",
      "[800]\tvalidation_0-rmse:0.17902\n",
      "[900]\tvalidation_0-rmse:0.17189\n",
      "[1000]\tvalidation_0-rmse:0.16647\n",
      "[1100]\tvalidation_0-rmse:0.16250\n",
      "[1200]\tvalidation_0-rmse:0.15935\n",
      "[1300]\tvalidation_0-rmse:0.15655\n",
      "[1400]\tvalidation_0-rmse:0.15443\n",
      "[1500]\tvalidation_0-rmse:0.15166\n",
      "[1600]\tvalidation_0-rmse:0.14856\n",
      "[1700]\tvalidation_0-rmse:0.14586\n",
      "[1800]\tvalidation_0-rmse:0.14340\n",
      "[1900]\tvalidation_0-rmse:0.14164\n",
      "[2000]\tvalidation_0-rmse:0.13968\n",
      "[2100]\tvalidation_0-rmse:0.13751\n",
      "[2200]\tvalidation_0-rmse:0.13501\n",
      "[2300]\tvalidation_0-rmse:0.13369\n",
      "[2400]\tvalidation_0-rmse:0.13251\n",
      "[2500]\tvalidation_0-rmse:0.13059\n",
      "[2600]\tvalidation_0-rmse:0.12951\n",
      "[2700]\tvalidation_0-rmse:0.12831\n",
      "[2800]\tvalidation_0-rmse:0.12690\n",
      "[2900]\tvalidation_0-rmse:0.12603\n",
      "[3000]\tvalidation_0-rmse:0.12554\n",
      "[3100]\tvalidation_0-rmse:0.12391\n",
      "[3200]\tvalidation_0-rmse:0.12329\n",
      "[3300]\tvalidation_0-rmse:0.12282\n",
      "[3400]\tvalidation_0-rmse:0.12248\n",
      "[3500]\tvalidation_0-rmse:0.12172\n",
      "[3600]\tvalidation_0-rmse:0.12075\n",
      "[3700]\tvalidation_0-rmse:0.12016\n",
      "[3800]\tvalidation_0-rmse:0.11935\n",
      "[3900]\tvalidation_0-rmse:0.11874\n",
      "[4000]\tvalidation_0-rmse:0.11822\n",
      "[4100]\tvalidation_0-rmse:0.11806\n",
      "[4200]\tvalidation_0-rmse:0.11788\n",
      "[4300]\tvalidation_0-rmse:0.11732\n",
      "[4400]\tvalidation_0-rmse:0.11686\n",
      "[4500]\tvalidation_0-rmse:0.11627\n",
      "[4600]\tvalidation_0-rmse:0.11588\n",
      "[4700]\tvalidation_0-rmse:0.11569\n",
      "[4800]\tvalidation_0-rmse:0.11557\n",
      "[4900]\tvalidation_0-rmse:0.11550\n",
      "[4999]\tvalidation_0-rmse:0.11539\n",
      "fold 2 MAE valid: 0.28\n",
      "[0]\tvalidation_0-rmse:0.49711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoto.ota/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-rmse:0.32984\n",
      "[200]\tvalidation_0-rmse:0.27034\n",
      "[300]\tvalidation_0-rmse:0.24216\n",
      "[400]\tvalidation_0-rmse:0.22400\n",
      "[500]\tvalidation_0-rmse:0.20891\n",
      "[600]\tvalidation_0-rmse:0.19643\n",
      "[700]\tvalidation_0-rmse:0.19044\n",
      "[800]\tvalidation_0-rmse:0.18267\n",
      "[900]\tvalidation_0-rmse:0.17517\n",
      "[1000]\tvalidation_0-rmse:0.17009\n",
      "[1100]\tvalidation_0-rmse:0.16526\n",
      "[1200]\tvalidation_0-rmse:0.16011\n",
      "[1300]\tvalidation_0-rmse:0.15502\n",
      "[1400]\tvalidation_0-rmse:0.15213\n",
      "[1500]\tvalidation_0-rmse:0.14919\n",
      "[1600]\tvalidation_0-rmse:0.14541\n",
      "[1700]\tvalidation_0-rmse:0.14360\n",
      "[1800]\tvalidation_0-rmse:0.14123\n",
      "[1900]\tvalidation_0-rmse:0.13919\n",
      "[2000]\tvalidation_0-rmse:0.13825\n",
      "[2100]\tvalidation_0-rmse:0.13567\n",
      "[2200]\tvalidation_0-rmse:0.13163\n",
      "[2300]\tvalidation_0-rmse:0.12911\n",
      "[2400]\tvalidation_0-rmse:0.12817\n",
      "[2500]\tvalidation_0-rmse:0.12608\n",
      "[2600]\tvalidation_0-rmse:0.12480\n",
      "[2700]\tvalidation_0-rmse:0.12358\n",
      "[2800]\tvalidation_0-rmse:0.12225\n",
      "[2900]\tvalidation_0-rmse:0.12144\n",
      "[3000]\tvalidation_0-rmse:0.12071\n",
      "[3100]\tvalidation_0-rmse:0.12039\n",
      "[3200]\tvalidation_0-rmse:0.11978\n",
      "[3300]\tvalidation_0-rmse:0.11872\n",
      "[3400]\tvalidation_0-rmse:0.11804\n",
      "[3500]\tvalidation_0-rmse:0.11773\n",
      "[3600]\tvalidation_0-rmse:0.11748\n",
      "[3700]\tvalidation_0-rmse:0.11722\n",
      "[3800]\tvalidation_0-rmse:0.11714\n",
      "[3900]\tvalidation_0-rmse:0.11669\n",
      "[4000]\tvalidation_0-rmse:0.11633\n",
      "[4100]\tvalidation_0-rmse:0.11586\n",
      "[4200]\tvalidation_0-rmse:0.11540\n",
      "[4300]\tvalidation_0-rmse:0.11516\n",
      "[4400]\tvalidation_0-rmse:0.11501\n",
      "[4500]\tvalidation_0-rmse:0.11489\n",
      "[4600]\tvalidation_0-rmse:0.11465\n",
      "[4700]\tvalidation_0-rmse:0.11459\n",
      "[4800]\tvalidation_0-rmse:0.11450\n",
      "[4900]\tvalidation_0-rmse:0.11431\n",
      "[4999]\tvalidation_0-rmse:0.11417\n",
      "fold 3 MAE valid: 0.28\n",
      "[0]\tvalidation_0-rmse:0.49707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoto.ota/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-rmse:0.32886\n",
      "[200]\tvalidation_0-rmse:0.27007\n",
      "[300]\tvalidation_0-rmse:0.23909\n",
      "[400]\tvalidation_0-rmse:0.21754\n",
      "[500]\tvalidation_0-rmse:0.20174\n",
      "[600]\tvalidation_0-rmse:0.19348\n",
      "[700]\tvalidation_0-rmse:0.18641\n",
      "[800]\tvalidation_0-rmse:0.18088\n",
      "[900]\tvalidation_0-rmse:0.17562\n",
      "[1000]\tvalidation_0-rmse:0.16920\n",
      "[1100]\tvalidation_0-rmse:0.16567\n",
      "[1200]\tvalidation_0-rmse:0.16193\n",
      "[1300]\tvalidation_0-rmse:0.15995\n",
      "[1400]\tvalidation_0-rmse:0.15688\n",
      "[1500]\tvalidation_0-rmse:0.15425\n",
      "[1600]\tvalidation_0-rmse:0.15202\n",
      "[1700]\tvalidation_0-rmse:0.14954\n",
      "[1800]\tvalidation_0-rmse:0.14515\n",
      "[1900]\tvalidation_0-rmse:0.14329\n",
      "[2000]\tvalidation_0-rmse:0.14151\n",
      "[2100]\tvalidation_0-rmse:0.13985\n",
      "[2200]\tvalidation_0-rmse:0.13770\n",
      "[2300]\tvalidation_0-rmse:0.13600\n",
      "[2400]\tvalidation_0-rmse:0.13396\n",
      "[2500]\tvalidation_0-rmse:0.13295\n",
      "[2600]\tvalidation_0-rmse:0.13139\n",
      "[2700]\tvalidation_0-rmse:0.12979\n",
      "[2800]\tvalidation_0-rmse:0.12874\n",
      "[2900]\tvalidation_0-rmse:0.12783\n",
      "[3000]\tvalidation_0-rmse:0.12725\n",
      "[3100]\tvalidation_0-rmse:0.12656\n",
      "[3200]\tvalidation_0-rmse:0.12606\n",
      "[3300]\tvalidation_0-rmse:0.12511\n",
      "[3400]\tvalidation_0-rmse:0.12442\n",
      "[3500]\tvalidation_0-rmse:0.12379\n",
      "[3600]\tvalidation_0-rmse:0.12302\n",
      "[3700]\tvalidation_0-rmse:0.12254\n",
      "[3800]\tvalidation_0-rmse:0.12142\n",
      "[3900]\tvalidation_0-rmse:0.12079\n",
      "[4000]\tvalidation_0-rmse:0.12008\n",
      "[4100]\tvalidation_0-rmse:0.11942\n",
      "[4200]\tvalidation_0-rmse:0.11895\n",
      "[4300]\tvalidation_0-rmse:0.11857\n",
      "[4400]\tvalidation_0-rmse:0.11810\n",
      "[4500]\tvalidation_0-rmse:0.11755\n",
      "[4600]\tvalidation_0-rmse:0.11696\n",
      "[4700]\tvalidation_0-rmse:0.11679\n",
      "[4800]\tvalidation_0-rmse:0.11662\n",
      "[4900]\tvalidation_0-rmse:0.11647\n",
      "[4999]\tvalidation_0-rmse:0.11625\n",
      "fold 4 MAE valid: 0.27\n",
      "[0]\tvalidation_0-rmse:0.49704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoto.ota/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-rmse:0.32972\n",
      "[200]\tvalidation_0-rmse:0.27122\n",
      "[300]\tvalidation_0-rmse:0.23987\n",
      "[400]\tvalidation_0-rmse:0.21851\n",
      "[500]\tvalidation_0-rmse:0.20308\n",
      "[600]\tvalidation_0-rmse:0.19382\n",
      "[700]\tvalidation_0-rmse:0.18766\n",
      "[800]\tvalidation_0-rmse:0.17917\n",
      "[900]\tvalidation_0-rmse:0.17259\n",
      "[1000]\tvalidation_0-rmse:0.16739\n",
      "[1100]\tvalidation_0-rmse:0.16349\n",
      "[1200]\tvalidation_0-rmse:0.16020\n",
      "[1300]\tvalidation_0-rmse:0.15794\n",
      "[1400]\tvalidation_0-rmse:0.15329\n",
      "[1500]\tvalidation_0-rmse:0.15102\n",
      "[1600]\tvalidation_0-rmse:0.14878\n",
      "[1700]\tvalidation_0-rmse:0.14574\n",
      "[1800]\tvalidation_0-rmse:0.14389\n",
      "[1900]\tvalidation_0-rmse:0.14226\n",
      "[2000]\tvalidation_0-rmse:0.14097\n",
      "[2100]\tvalidation_0-rmse:0.13808\n",
      "[2200]\tvalidation_0-rmse:0.13591\n",
      "[2300]\tvalidation_0-rmse:0.13449\n",
      "[2400]\tvalidation_0-rmse:0.13355\n",
      "[2500]\tvalidation_0-rmse:0.13312\n",
      "[2600]\tvalidation_0-rmse:0.13244\n",
      "[2700]\tvalidation_0-rmse:0.13029\n",
      "[2800]\tvalidation_0-rmse:0.12857\n",
      "[2900]\tvalidation_0-rmse:0.12768\n",
      "[3000]\tvalidation_0-rmse:0.12675\n",
      "[3100]\tvalidation_0-rmse:0.12538\n",
      "[3200]\tvalidation_0-rmse:0.12326\n",
      "[3300]\tvalidation_0-rmse:0.12132\n",
      "[3400]\tvalidation_0-rmse:0.12039\n",
      "[3500]\tvalidation_0-rmse:0.11928\n",
      "[3600]\tvalidation_0-rmse:0.11829\n",
      "[3700]\tvalidation_0-rmse:0.11734\n",
      "[3800]\tvalidation_0-rmse:0.11688\n",
      "[3900]\tvalidation_0-rmse:0.11620\n",
      "[4000]\tvalidation_0-rmse:0.11585\n",
      "[4100]\tvalidation_0-rmse:0.11538\n",
      "[4200]\tvalidation_0-rmse:0.11488\n",
      "[4300]\tvalidation_0-rmse:0.11469\n",
      "[4400]\tvalidation_0-rmse:0.11459\n",
      "[4500]\tvalidation_0-rmse:0.11446\n",
      "[4600]\tvalidation_0-rmse:0.11427\n",
      "[4700]\tvalidation_0-rmse:0.11403\n",
      "[4800]\tvalidation_0-rmse:0.11375\n",
      "[4900]\tvalidation_0-rmse:0.11365\n",
      "[4999]\tvalidation_0-rmse:0.11323\n",
      "fold 5 MAE valid: 0.26\n",
      "Average MAE across all folds: 0.27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def crossVal(X_train, y_train, xgb_params):\n",
    "    valid_scores = []\n",
    "    models = []\n",
    "    oof = np.zeros(len(X_train))\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X_train)):\n",
    "        X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "        y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "\n",
    "        model = xgb.XGBRegressor(**xgb_params, enable_categorical=True)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr)], early_stopping_rounds=50, verbose=100)\n",
    "        y_va_pred = model.predict(X_va)  # 予測値の計算\n",
    "\n",
    "        score = mean_absolute_error(y_va, y_va_pred)\n",
    "        print(f'fold {fold+1} MAE valid: {score:.2f}')\n",
    "\n",
    "        valid_scores.append(score)\n",
    "        models.append(model)\n",
    "        oof[va_idx] = y_va_pred\n",
    "\n",
    "    return valid_scores, models, oof\n",
    "\n",
    "# クロスバリデーションの平均スコア\n",
    "valid_scores, models_xg, oof = crossVal(X_train, y_train, xgb_params)\n",
    "print(f'Average MAE across all folds: {np.mean(valid_scores):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータで検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(submi_data,models):\n",
    "    output = np.zeros_like(models[0].predict(submi_data))\n",
    "    for i in range(len(models)):\n",
    "        output += models[i].predict(submi_data)\n",
    "       \n",
    "        \n",
    "    output = output / len(models)\n",
    "    return np.round(output).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble = models_xg + models_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7975848189\n",
      "precision = 0.8059360731\n",
      "recall = 0.7950450450\n",
      "F1-score = 0.8004535147\n"
     ]
    }
   ],
   "source": [
    "ac_score = accuracy_score(predict(X_test,model_ensemble), y_test)\n",
    "pr_score = precision_score(predict(X_test,model_ensemble), y_test)\n",
    "rc_score = recall_score(predict(X_test,model_ensemble), y_test)\n",
    "f1 = f1_score(predict(X_test,model_ensemble), y_test)\n",
    "\n",
    "print('accuracy = %.10f' % (ac_score))\n",
    "print('precision = %.10f' % (pr_score))\n",
    "print('recall = %.10f' % (rc_score))\n",
    "print('F1-score = %.10f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
